{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: Variance reduction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from src.my_random import gen\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return np.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "runs = 10000\n",
    "areas = []\n",
    "\n",
    "for i in range(runs):\n",
    "    xrand = stats.uniform.rvs(size=N)\n",
    "    areas.append(func(xrand))\n",
    "\n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the crude Monte Carlo estimator is: ',m)\n",
    "print('While the confidence interval at 95%','confidence is:',confInt)\n",
    "\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "runs = 10000\n",
    "areas = []\n",
    "\n",
    "\n",
    "for i in range(runs):\n",
    "    urand = stats.uniform.rvs(size=N)\n",
    "    areas.append(np.mean((func(urand)+func(1)/func(urand))/2))\n",
    "\n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the antithetic Monte Carlo estimator is: ',m)\n",
    "print('While the confidence interval at 95%',' confidence is:',confInt)\n",
    "\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "runs = 10000\n",
    "areas = []\n",
    "\n",
    "for i in range(runs):\n",
    "    urand = stats.uniform.rvs(size=N)\n",
    "    X = np.zeros(N)\n",
    "    mu = 0.5\n",
    "    #c = -(np.mean(urand*func(urand))-np.mean(urand)*np.mean(func(urand)))/np.var(urand)\n",
    "    c = 0.0039\n",
    "    areas.append(np.mean(np.sum(func(urand) + c*(urand-mu))))\n",
    "\n",
    "    \n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the Monte Carlo estimator using a control variable is: ',m)\n",
    "print('While the confidence interval at 95%','confidence is:',confInt)\n",
    "\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=1\n",
    "N = 100\n",
    "strata = 10\n",
    "runs = 10000\n",
    "areas = []\n",
    "\n",
    "for i in range(runs):\n",
    "    urand = np.zeros((N,strata))\n",
    "    for i in range(N):\n",
    "        for j in range(strata):\n",
    "            urand[i][j] = random.uniform(a,b)\n",
    "    W = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(strata):\n",
    "            W += func((urand[i][j]+j)/strata)/strata\n",
    "    \n",
    "    areas.append(W/float(N))\n",
    "\n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the Monte Carlo estimator using stratified sampling is: ',m)\n",
    "print('While the confidence interval at 95%','confidence is:',confInt)\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.my_random.eventBis import BlockingEventSimulation, calculate_theoretical_block_pct\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr_dist = stats.expon()\n",
    "\n",
    "serv_dist = stats.expon(scale=8)\n",
    "pois_sim = BlockingEventSimulation(arr_dist, serv_dist)\n",
    "blocked = []\n",
    "for i in range(10):\n",
    "    blocked.append(pois_sim.simulate(10_000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(blocked)\n",
    "sd = np.std(blocked)\n",
    "lwr, upr = stats.t.interval(0.95, 9)\n",
    "conf = [mean + sd/np.sqrt(10)*lwr, mean + sd/np.sqrt(10)*upr]\n",
    "\n",
    "mean, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=233423)\n",
    "urand = stats.uniform.rvs(size=1000)\n",
    "xrand = func(urand)\n",
    "np.random.seed(seed=233423)\n",
    "arr_times = stats.expon.rvs(size=1000)\n",
    "exponE = arr_times.mean()\n",
    "exponVar = arr_times.var()\n",
    "uniE = xrand.mean()\n",
    "uniVar = xrand.var()\n",
    "\n",
    "print('Exponential dist E:',exponE,'and Var:',exponVar)\n",
    "print('Unif dist into exponential E:',exponE,'and Var:',exponVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_theoretical_block_pct(10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusing the same random seed we compare the prior results with hyperexponential interarrival times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class hyper_exp:\n",
    "    p1: float\n",
    "    p2: float\n",
    "    lmbda1: float\n",
    "    lmbda2: float\n",
    "\n",
    "    def rvs(self, size):\n",
    "        np.random.seed(seed=233423)\n",
    "        return self.p1 * stats.expon.rvs(size=size, scale=1/self.lmbda1) \\\n",
    "            + self.p2*stats.expon.rvs(size=size, scale = 1/self.lmbda2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_erl = stats.erlang(a=1)\n",
    "arr_hyp = hyper_exp(0.8, .2, .8333, 5.0)\n",
    "serv_dist = stats.expon(scale=8)\n",
    "\n",
    "sim_erl = BlockingEventSimulation(arr_erl, serv_dist)\n",
    "sim_hyp = BlockingEventSimulation(arr_hyp, serv_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked = []\n",
    "for i in range(10):\n",
    "    blocked.append(sim_erl.simulate(10_000, 10))\n",
    "\n",
    "mean = np.mean(blocked)\n",
    "sd = np.std(blocked)\n",
    "lwr, upr = stats.t.interval(0.95, 9)\n",
    "conf = [mean + sd/np.sqrt(10)*lwr, mean + sd/np.sqrt(10)*upr]\n",
    "\n",
    "mean, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "max = 1\n",
    "sig2 = 1\n",
    "N = 100\n",
    "runs = 10000\n",
    "areas = []\n",
    "np.random.seed()\n",
    "\n",
    "for _ in range(runs):\n",
    "    xrand = stats.norm.rvs(size=N)\n",
    "    areas.append(np.mean(func(xrand)))\n",
    "\n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the crude Monte Carlo estimator is: ',m)\n",
    "print('While the confidence interval at 95%','confidence is:',confInt,'also this here',s*t/np.sqrt(N))\n",
    "\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 0\n",
    "max = 1\n",
    "a = (0,2,4)\n",
    "sig2 = 1\n",
    "N = 100\n",
    "runs = 10000\n",
    "areas = np.zeros((len(a),runs))\n",
    "np.random.seed()\n",
    "\n",
    "for k in range(len(a)):\n",
    "    for i in range(runs):\n",
    "        xrand = stats.norm.rvs(size=N)\n",
    "        frand = stats.norm.pdf(xrand)\n",
    "        grand = stats.norm.pdf(xrand,loc=a[k],scale=1)\n",
    "        integral = 0.0\n",
    "        for j in range(N):\n",
    "            integral += np.exp(xrand[j])*frand[j]/grand[j]\n",
    "        areas[k][i]=(integral/float(N))*(max-min)\n",
    "    m = np.mean(areas[k])\n",
    "    s = np.std(areas[k])\n",
    "    dof = N-1\n",
    "    conf = 0.95\n",
    "    t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "    confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "    print('The point estimate of the crude Monte Carlo estimator is: ',m)\n",
    "    print('While the confidence interval at 95%','confidence is:',confInt,'with a =',a[k])\n",
    "\n",
    "\n",
    "plt.hist(areas[0], bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min = 0\n",
    "max = 1\n",
    "sig2 = 1\n",
    "N = 100\n",
    "runs = 10000\n",
    "areas = []\n",
    "lamb = -0.6835\n",
    "np.random.seed()\n",
    "\n",
    "for _ in range(runs):\n",
    "    xrand = stats.uniform.rvs(size=N)\n",
    "    frand = stats.uniform.pdf(xrand)\n",
    "    grand = lamb*np.exp(-lamb*xrand)\n",
    "    areas.append(np.abs(np.mean(np.exp(xrand)*frand/(grand))))\n",
    "\n",
    "m = np.mean(areas)\n",
    "s = np.std(areas)\n",
    "dof = N-1\n",
    "conf = 0.95\n",
    "\n",
    "\n",
    "\n",
    "t = np.abs(stats.t.ppf((1-conf)/2,dof))\n",
    "confInt = (m-s*t/np.sqrt(N),m+s*t/np.sqrt(N))\n",
    "print('The point estimate of the crude Monte Carlo estimator is: ',m)\n",
    "print('While the confidence interval at 95%','confidence is:',confInt)\n",
    "\n",
    "plt.hist(areas, bins=30, ec= 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\n",
    "For the pareto case, using the First moment distribution of the pareto as sampling distribution, we derive the expected mean of the IS estimator to be equal to the theoretical mean. Should one know the first moment distribution of a distribution one is attempting to approximate, implementing the first moment as a sampling distribution would in theory make sense should the expected value be unknown and more difficult to compute.\n",
    "\n",
    "$$\\frac{x\\frac{k\\beta^k}{x^{k+1}}}{\\frac{(k-1)\\beta^{k-1}}{x^k}}=\\frac{k}{k-1}\\beta$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a71a9e4fb054fff428071484f7faa898cb9ecb31a518fe88e3463da9af879578"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
